{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 00:19:37.809838: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-21 00:19:38.127282: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-21 00:19:38.147443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-21 00:19:38.147467: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-03-21 00:19:39.240788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-21 00:19:39.240928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-21 00:19:39.240935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import os\n",
    "import random\n",
    "from ppo_agents import WordleFeatureExtractor, WordleFeatureExtractor_Markov\n",
    "from environments import WordleEnv, WordleEnvMarkov  \n",
    "from trainer import WordleTrainingCallback\n",
    "from heuristics import HeuristicWordleAgent\n",
    "\n",
    "def make_env(word_list_path, rank=0):\n",
    "    \"\"\"\n",
    "    Create a WordleEnv environment for Stable Baselines3.\n",
    "    \n",
    "    Args:\n",
    "        word_list_path: Path to the word list file\n",
    "        rank: Environment rank (for vectorized environments)\n",
    "        \n",
    "    Returns:\n",
    "        A function that creates an instance of the environment\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = WordleEnvMarkov(word_list_path, max_attempts=6, word_length=5)\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "\n",
    "def train_ppo_agent(word_list_path, total_timesteps=100000, log_dir='./logs'):\n",
    "    \"\"\"\n",
    "    Train a PPO agent on the Wordle environment.\n",
    "    \n",
    "    Args:\n",
    "        word_list_path: Path to the word list file\n",
    "        total_timesteps: Number of training steps\n",
    "        log_dir: Directory to save logs\n",
    "        \n",
    "    Returns:\n",
    "        The trained PPO model\n",
    "    \"\"\"\n",
    "    # Create environments\n",
    "    env = DummyVecEnv([make_env(word_list_path)])\n",
    "    env = VecNormalize(env, norm_obs=False, norm_reward=True)\n",
    "    \n",
    "    eval_env = DummyVecEnv([make_env(word_list_path)])\n",
    "    eval_env = VecNormalize(eval_env, norm_obs=False, norm_reward=True, training=False)\n",
    "    \n",
    "    # Policy kwargs for the feature extractor\n",
    "    policy_kwargs = {\n",
    "        'features_extractor_class': WordleFeatureExtractor_Markov,\n",
    "        'features_extractor_kwargs': {'features_dim': 256}\n",
    "    }\n",
    "    \n",
    "    # Create the PPO agent\n",
    "    model = PPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.01,\n",
    "        tensorboard_log=log_dir\n",
    "    )\n",
    "    \n",
    "    # Create the callback\n",
    "    callback = WordleTrainingCallback(eval_env, check_freq=5000, log_dir=log_dir)\n",
    "    \n",
    "    # Train the agent\n",
    "    model.learn(total_timesteps=total_timesteps, callback=callback)\n",
    "    \n",
    "    # Plot training metrics\n",
    "    callback.plot_metrics()\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(os.path.join(log_dir, \"ppo_wordle\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_ppo_agent(model, word_list_path, num_episodes=50, render=True):\n",
    "    \"\"\"\n",
    "    Evaluate a trained PPO agent on the Wordle environment.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained PPO model\n",
    "        word_list_path: Path to the word list file\n",
    "        num_episodes: Number of episodes to evaluate\n",
    "        render: Whether to render the environment\n",
    "        \n",
    "    Returns:\n",
    "        Evaluation results\n",
    "    \"\"\"\n",
    "    # Create the evaluation environment\n",
    "    eval_env = WordleEnvMarkov(word_list_path, max_attempts=6, word_length=5, render_mode=\"human\" if render else None)\n",
    "    \n",
    "    # Load word list\n",
    "    try:\n",
    "        with open(word_list_path, 'r') as f:\n",
    "            words = [w.strip().lower() for w in f.readlines() if len(w.strip()) == 5 and w.strip().isalpha()]\n",
    "    except FileNotFoundError:\n",
    "        # Use sample words if file doesn't exist\n",
    "        print(f\"Warning: {word_list_path} not found. Using a small sample of words.\")\n",
    "        words = [\n",
    "            'apple', 'baker', 'child', 'dance', 'early', 'first', 'grand', 'house', 'input',\n",
    "            'jolly', 'knife', 'light', 'mouse', 'night', 'ocean', 'piano', 'queen', 'river',\n",
    "            'sound', 'table', 'under', 'value', 'water', 'xenon', 'youth', 'zebra'\n",
    "        ]\n",
    "    \n",
    "    # Evaluate the agent\n",
    "    wins = 0\n",
    "    rewards = []\n",
    "    attempts = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = eval_env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        used_words = []\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            # Get the word\n",
    "            word = words[action]\n",
    "            if word in used_words:\n",
    "                # If we've already used this word, pick a random unused word\n",
    "                unused_words = [w for w in words if w not in used_words]\n",
    "                if unused_words:\n",
    "                    word = random.choice(unused_words)\n",
    "                    action = words.index(word)\n",
    "                \n",
    "            used_words.append(word)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "            episode_reward += reward\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            if render:\n",
    "                eval_env.render()\n",
    "        \n",
    "        rewards.append(episode_reward)\n",
    "        won = eval_env.won\n",
    "        wins += 1 if won else 0\n",
    "        if won:\n",
    "            attempts.append(eval_env.current_attempt)\n",
    "        \n",
    "        if render:\n",
    "            print(f\"Episode {episode+1}/{num_episodes} | \" +\n",
    "                  f\"Result: {'Won' if won else 'Lost'} | \" +\n",
    "                  f\"Word: {eval_env.target_word} | \" +\n",
    "                  f\"Attempts: {eval_env.current_attempt}/{eval_env.max_attempts}\" +\n",
    "                  f\" | Reward: {episode_reward:.2f}\")\n",
    "    \n",
    "    win_rate = wins / num_episodes\n",
    "    avg_reward = sum(rewards) / num_episodes\n",
    "    avg_attempts = sum(attempts) / len(attempts) if attempts else 0\n",
    "    \n",
    "    print(f\"\\nEvaluation Results:\")\n",
    "    print(f\"Win Rate: {win_rate:.2f}\")\n",
    "    print(f\"Average Reward: {avg_reward:.2f}\")\n",
    "    print(f\"Average Attempts (when won): {avg_attempts:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'win_rate': win_rate,\n",
    "        'avg_reward': avg_reward,\n",
    "        'avg_attempts': avg_attempts\n",
    "    }\n",
    "\n",
    "\n",
    "def compare_with_heuristic(model, word_list_path, num_episodes=50):\n",
    "    \"\"\"\n",
    "    Compare the PPO agent with a heuristic agent.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained PPO model\n",
    "        word_list_path: Path to the word list file\n",
    "        num_episodes: Number of episodes for comparison\n",
    "        \n",
    "    Returns:\n",
    "        Comparison results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load word list\n",
    "    try:\n",
    "        with open(word_list_path, 'r') as f:\n",
    "            words = [w.strip().lower() for w in f.readlines() if len(w.strip()) == 5 and w.strip().isalpha()]\n",
    "    except FileNotFoundError:\n",
    "        # Use sample words if file doesn't exist\n",
    "        print(f\"Warning: {word_list_path} not found. Using a small sample of words.\")\n",
    "        words = [\n",
    "            'apple', 'baker', 'child', 'dance', 'early', 'first', 'grand', 'house', 'input',\n",
    "            'jolly', 'knife', 'light', 'mouse', 'night', 'ocean', 'piano', 'queen', 'river',\n",
    "            'sound', 'table', 'under', 'value', 'water', 'xenon', 'youth', 'zebra'\n",
    "        ]\n",
    "    \n",
    "    # Create the heuristic agent\n",
    "    heuristic_agent = HeuristicWordleAgent(words)\n",
    "    \n",
    "    # Create environment\n",
    "    env = WordleEnvMarkov(word_list_path, max_attempts=6, word_length=5)\n",
    "    \n",
    "    # Generate random target words\n",
    "    target_words = random.sample(words, min(num_episodes, len(words)))\n",
    "    \n",
    "    # Evaluate both agents\n",
    "    results = {\n",
    "        'ppo': {'wins': 0, 'attempts': []},\n",
    "        'heuristic': {'wins': 0, 'attempts': []}\n",
    "    }\n",
    "    \n",
    "    for i, target_word in enumerate(target_words):\n",
    "        print(f\"\\nGame {i+1}/{num_episodes} - Target word: {target_word}\")\n",
    "        \n",
    "        # Evaluate PPO agent\n",
    "        obs, _ = env.reset(options={'target_word': target_word})\n",
    "        done = False\n",
    "        used_words = []\n",
    "        \n",
    "        print(\"PPO agent playing...\")\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            word = words[action]\n",
    "            \n",
    "            # Avoid repeated words\n",
    "            if word in used_words:\n",
    "                unused_words = [w for w in words if w not in used_words]\n",
    "                if unused_words:\n",
    "                    word = random.choice(unused_words)\n",
    "                    action = words.index(word)\n",
    "            \n",
    "            used_words.append(word)\n",
    "            obs, _, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "        \n",
    "        ppo_won = env.won\n",
    "        ppo_attempts = env.current_attempt\n",
    "        results['ppo']['wins'] += 1 if ppo_won else 0\n",
    "        if ppo_won:\n",
    "            results['ppo']['attempts'].append(ppo_attempts)\n",
    "        \n",
    "        print(f\"PPO result: {'Won' if ppo_won else 'Lost'} in {ppo_attempts} attempts\")\n",
    "        \n",
    "        # Evaluate heuristic agent\n",
    "        heuristic_agent.reset()\n",
    "        env.reset(options={'target_word': target_word})\n",
    "        \n",
    "        print(\"Heuristic agent playing...\")\n",
    "        for attempt in range(env.max_attempts):\n",
    "            guess = heuristic_agent.get_action()\n",
    "            action = words.index(guess) if guess in words else 0\n",
    "            \n",
    "            obs, _, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            \n",
    "            # Generate feedback\n",
    "            feedback = []\n",
    "            for j in range(env.word_length):\n",
    "                if env.board[attempt, j, env.CORRECT] == 1:\n",
    "                    feedback.append(2)  # Correct\n",
    "                elif env.board[attempt, j, env.PRESENT] == 1:\n",
    "                    feedback.append(1)  # Present\n",
    "                else:\n",
    "                    feedback.append(0)  # Absent\n",
    "            \n",
    "            heuristic_agent.update(guess, feedback)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        heuristic_won = env.won\n",
    "        heuristic_attempts = env.current_attempt\n",
    "        results['heuristic']['wins'] += 1 if heuristic_won else 0\n",
    "        if heuristic_won:\n",
    "            results['heuristic']['attempts'].append(heuristic_attempts)\n",
    "        \n",
    "        print(f\"Heuristic result: {'Won' if heuristic_won else 'Lost'} in {heuristic_attempts} attempts\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    ppo_win_rate = results['ppo']['wins'] / num_episodes\n",
    "    heuristic_win_rate = results['heuristic']['wins'] / num_episodes\n",
    "    \n",
    "    ppo_avg_attempts = sum(results['ppo']['attempts']) / len(results['ppo']['attempts']) if results['ppo']['attempts'] else 0\n",
    "    heuristic_avg_attempts = sum(results['heuristic']['attempts']) / len(results['heuristic']['attempts']) if results['heuristic']['attempts'] else 0\n",
    "    \n",
    "    print(\"\\nComparison Results:\")\n",
    "    print(f\"PPO Win Rate: {ppo_win_rate:.2f}\")\n",
    "    print(f\"Heuristic Win Rate: {heuristic_win_rate:.2f}\")\n",
    "    print(f\"PPO Average Attempts (when won): {ppo_avg_attempts:.2f}\")\n",
    "    print(f\"Heuristic Average Attempts (when won): {heuristic_avg_attempts:.2f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PPO agent...\n",
      "Using cpu device\n",
      "Logging to ./logs/ppo_wordle/PPO_20\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.97     |\n",
      "|    ep_rew_mean     | 67.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 118      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27761/1054796733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training PPO agent...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ppo_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_wordle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEvaluating PPO agent...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27761/537117438.py\u001b[0m in \u001b[0;36mtrain_ppo_agent\u001b[0;34m(word_list_path, total_timesteps, log_dir)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Train the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Plot training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 311\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dump_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# Normalize advantage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mevaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \"\"\"\n\u001b[1;32m    729\u001b[0m         \u001b[0;31m# Preprocess the observation if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_features_extractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \"\"\"\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_features_extractor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeatures_extractor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeatures_extractor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m    130\u001b[0m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_constructor_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Rl4Wordle/ppo_agents.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mother_letter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mother_letter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mletter_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_letter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0;31m# Redistribute weight for yellows if this letter became green\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_list_path = \"target_words.txt\"\n",
    "log_dir = \"./logs/ppo_wordle\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "print(\"Training PPO agent...\")\n",
    "model = train_ppo_agent(word_list_path, total_timesteps=100000, log_dir=log_dir)\n",
    "model.save(\"ppo_wordle\")\n",
    "print(\"\\nEvaluating PPO agent...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬛🟨⬛⬛🟨\n",
      "Attempt 6/6\n",
      "Game over! The word was: rally\n",
      "Episode 1/20 | Result: Lost | Word: rally | Attempts: 6/6 | Reward: 0.00\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟩⬛🟩\n",
      "Attempt 6/6\n",
      "Game over! The word was: sunny\n",
      "Episode 2/20 | Result: Lost | Word: sunny | Attempts: 6/6 | Reward: 1.40\n",
      "⬛⬛🟨🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛🟨🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛🟨🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛🟨🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛🟨🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛🟨🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛⬛⬛🟩⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: mimic\n",
      "Episode 3/20 | Result: Lost | Word: mimic | Attempts: 6/6 | Reward: 0.90\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: awake\n",
      "Episode 4/20 | Result: Lost | Word: awake | Attempts: 6/6 | Reward: 1.00\n",
      "⬛⬛⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛🟨⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛🟨⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛🟨⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛🟨⬛⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: hello\n",
      "Episode 5/20 | Result: Lost | Word: hello | Attempts: 6/6 | Reward: 0.60\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬛🟨⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛🟩\n",
      "⬛⬛⬛⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬛🟨⬛⬛🟩\n",
      "🟨⬛⬛⬛🟩\n",
      "Attempt 6/6\n",
      "Game over! The word was: hence\n",
      "Episode 6/20 | Result: Lost | Word: hence | Attempts: 6/6 | Reward: 1.40\n",
      "⬛⬛🟩⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛🟩⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛🟩⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛🟩⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛🟩⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛🟩⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: avian\n",
      "Episode 7/20 | Result: Lost | Word: avian | Attempts: 6/6 | Reward: 0.20\n",
      "⬛⬛⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "🟩⬛⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "🟩⬛⬛🟨⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "🟩⬛⬛🟨⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "🟩⬛⬛🟨⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: magma\n",
      "Episode 8/20 | Result: Lost | Word: magma | Attempts: 6/6 | Reward: 0.50\n",
      "⬛🟨🟨⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛🟨🟨⬛🟨\n",
      "🟨⬛⬛🟩🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛🟨🟨⬛🟨\n",
      "🟨⬛⬛🟩🟩\n",
      "⬛🟩🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛🟨🟨⬛🟨\n",
      "🟨⬛⬛🟩🟩\n",
      "⬛🟩🟨⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛🟨🟨⬛🟨\n",
      "🟨⬛⬛🟩🟩\n",
      "⬛🟩🟨⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛🟨🟨⬛🟨\n",
      "🟨⬛⬛🟩🟩\n",
      "⬛🟩🟨⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛⬛⬛⬛🟨\n",
      "Attempt 6/6\n",
      "Game over! The word was: cider\n",
      "Episode 9/20 | Result: Lost | Word: cider | Attempts: 6/6 | Reward: 2.10\n",
      "⬛🟨⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛⬛⬛🟩🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛🟩🟩🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛🟩🟩🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛🟩🟩🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛🟨⬛⬛🟨\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛⬛🟩🟩🟩\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛🟩🟩\n",
      "⬛🟩⬛⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: later\n",
      "Episode 10/20 | Result: Lost | Word: later | Attempts: 6/6 | Reward: 2.90\n",
      "⬛⬛⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨🟩⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨🟩⬛⬛🟨\n",
      "⬛🟩⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨🟩⬛⬛🟨\n",
      "⬛🟩⬛🟩⬛\n",
      "⬛⬛⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨🟩⬛⬛🟨\n",
      "⬛🟩⬛🟩⬛\n",
      "⬛⬛⬛⬛🟩\n",
      "🟨⬛⬛🟨⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: teeth\n",
      "Episode 11/20 | Result: Lost | Word: teeth | Attempts: 6/6 | Reward: 1.60\n",
      "⬛⬛⬛🟨🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛🟨🟨\n",
      "🟨⬛⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛🟨🟨\n",
      "🟨⬛⬛⬛🟨\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛🟨🟨\n",
      "🟨⬛⬛⬛🟨\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛🟨🟨\n",
      "🟨⬛⬛⬛🟨\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛🟨🟨\n",
      "🟨⬛⬛⬛🟨\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛⬛⬛🟩⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: lumen\n",
      "Episode 12/20 | Result: Lost | Word: lumen | Attempts: 6/6 | Reward: 0.50\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛🟨⬛⬛⬛\n",
      "🟩🟩⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛🟨⬛⬛⬛\n",
      "🟩🟩⬛🟩⬛\n",
      "🟩⬛⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛🟨⬛⬛⬛\n",
      "🟩🟩⬛🟩⬛\n",
      "🟩⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛🟨⬛⬛⬛\n",
      "🟩🟩⬛🟩⬛\n",
      "🟩⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛🟨⬛⬛⬛\n",
      "🟩🟩⬛🟩⬛\n",
      "🟩⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "🟩🟨🟨🟩⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: corny\n",
      "Episode 13/20 | Result: Lost | Word: corny | Attempts: 6/6 | Reward: 2.80\n",
      "⬛⬛⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨🟩⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨🟩⬛🟨⬛\n",
      "⬛⬛⬛⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨🟩⬛🟨⬛\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛🟩⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨🟩⬛🟨⬛\n",
      "⬛⬛⬛⬛🟨\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨🟩⬛⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: comma\n",
      "Episode 14/20 | Result: Lost | Word: comma | Attempts: 6/6 | Reward: 1.20\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨🟨⬛⬛\n",
      "⬛⬛⬛🟨⬛\n",
      "🟨⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: basin\n",
      "Episode 15/20 | Result: Lost | Word: basin | Attempts: 6/6 | Reward: 0.10\n",
      "⬛⬛🟨⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛🟨⬛🟩\n",
      "⬛🟨⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛🟨⬛🟩\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛🟨⬛🟩\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛🟨⬛🟩\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛🟩\n",
      "🟩⬛⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛🟨⬛🟩\n",
      "⬛🟨⬛🟨⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛🟩\n",
      "🟩⬛⬛🟩⬛\n",
      "🟨⬛⬛🟨🟩\n",
      "Attempt 6/6\n",
      "Game over! The word was: wince\n",
      "Episode 16/20 | Result: Lost | Word: wince | Attempts: 6/6 | Reward: 2.00\n",
      "⬛⬛🟨⬛🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛🟨⬛🟨\n",
      "⬛🟨⬛⬛🟩\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛🟨⬛🟨\n",
      "⬛🟨⬛⬛🟩\n",
      "⬛⬛⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛🟨⬛🟨\n",
      "⬛🟨⬛⬛🟩\n",
      "⬛⬛⬛🟨⬛\n",
      "⬛🟨🟨🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛🟨⬛🟨\n",
      "⬛🟨⬛⬛🟩\n",
      "⬛⬛⬛🟨⬛\n",
      "⬛🟨🟨🟨⬛\n",
      "⬛🟨⬛🟩⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛🟨⬛🟨\n",
      "⬛🟨⬛⬛🟩\n",
      "⬛⬛⬛🟨⬛\n",
      "⬛🟨🟨🟨⬛\n",
      "⬛🟨⬛🟩⬛\n",
      "⬛⬛🟨🟨⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: islet\n",
      "Episode 17/20 | Result: Lost | Word: islet | Attempts: 6/6 | Reward: 1.20\n",
      "⬛🟩🟩⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛🟩🟩⬛⬛\n",
      "⬛🟩🟩⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛🟩🟩⬛⬛\n",
      "⬛🟩🟩⬛⬛\n",
      "🟨⬛🟩⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛🟩🟩⬛⬛\n",
      "⬛🟩🟩⬛⬛\n",
      "🟨⬛🟩⬛⬛\n",
      "🟨🟩⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛🟩🟩⬛⬛\n",
      "⬛🟩🟩⬛⬛\n",
      "🟨⬛🟩⬛⬛\n",
      "🟨🟩⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛🟩🟩⬛⬛\n",
      "⬛🟩🟩⬛⬛\n",
      "🟨⬛🟩⬛⬛\n",
      "🟨🟩⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "🟨🟩🟩⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: fritz\n",
      "Episode 18/20 | Result: Lost | Word: fritz | Attempts: 6/6 | Reward: 2.90\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬛⬛⬛🟨🟨\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬛⬛⬛🟨🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "🟨⬛🟨⬛⬛\n",
      "⬛⬛⬛🟨🟨\n",
      "⬛⬛⬛🟨⬛\n",
      "⬛⬛🟨⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: coast\n",
      "Episode 19/20 | Result: Lost | Word: coast | Attempts: 6/6 | Reward: 0.10\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 1/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 2/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 3/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 4/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬜⬜⬜⬜⬜\n",
      "Attempt 5/6\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "⬛🟨⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛🟩⬛⬛⬛\n",
      "⬛⬛⬛⬛⬛\n",
      "Attempt 6/6\n",
      "Game over! The word was: slush\n",
      "Episode 20/20 | Result: Lost | Word: slush | Attempts: 6/6 | Reward: 0.30\n",
      "\n",
      "Evaluation Results:\n",
      "Win Rate: 0.00\n",
      "Average Reward: 1.19\n",
      "Average Attempts (when won): 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'win_rate': 0.0, 'avg_reward': np.float32(1.1850001), 'avg_attempts': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO.load(\"ppo_wordle2025-03-19_21-20-40.zip\")\n",
    "evaluate_ppo_agent(model, word_list_path, num_episodes=20, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing with heuristic agent...\n",
      "\n",
      "Game 1/20 - Target word: visit\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 2/20 - Target word: filer\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 3/20 - Target word: axiom\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Won in 2 attempts\n",
      "\n",
      "Game 4/20 - Target word: sworn\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 5/20 - Target word: carry\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 6/20 - Target word: hunch\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 7/20 - Target word: flail\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Won in 3 attempts\n",
      "\n",
      "Game 8/20 - Target word: small\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 9/20 - Target word: pasta\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 10/20 - Target word: claim\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 11/20 - Target word: ideal\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 12/20 - Target word: count\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 13/20 - Target word: gaudy\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 14/20 - Target word: ashen\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 15/20 - Target word: fritz\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 16/20 - Target word: genre\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 17/20 - Target word: ruder\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Won in 3 attempts\n",
      "\n",
      "Game 18/20 - Target word: level\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 19/20 - Target word: eight\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Game 20/20 - Target word: ounce\n",
      "PPO agent playing...\n",
      "PPO result: Lost in 6 attempts\n",
      "Heuristic agent playing...\n",
      "Heuristic result: Lost in 6 attempts\n",
      "\n",
      "Comparison Results:\n",
      "PPO Win Rate: 0.00\n",
      "Heuristic Win Rate: 0.15\n",
      "PPO Average Attempts (when won): 0.00\n",
      "Heuristic Average Attempts (when won): 2.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ppo': {'wins': 0, 'attempts': []},\n",
       " 'heuristic': {'wins': 3, 'attempts': [2, 3, 3]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compare with heuristic agent\n",
    "print(\"\\nComparing with heuristic agent...\")\n",
    "compare_with_heuristic(model, word_list_path, num_episodes=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
